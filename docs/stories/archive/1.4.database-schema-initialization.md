# Story 1.4: Database Schema Initialization

## Status
Ready for Review

## Story
**As a** developer,
**I want** the initial database schemas for both SQLite and Supabase defined and creatable,
**so that** the application has a persistent data layer to connect to.

## Acceptance Criteria
1. An SQL script is created that defines the tables for the local SQLite database (`users`, `documents`, etc.).
2. An SQL script is created that defines the tables for the Supabase (PostgreSQL) database and enables the `pgvector` extension.
3. Instructions are documented for applying these schemas to the respective databases.

## Tasks / Subtasks
- [x] Task 1: Create SQLite schema script (AC: 1)
  - [x] Create `apps/api/database/` directory for database files
  - [x] Define `users` table with authentication fields (id, email, password_hash, role, status, created_at, updated_at)
  - [x] Define `documents` table with metadata fields (id, filename, document_type, file_path, status, created_at, updated_at)
  - [x] Define `processing_jobs` table for job tracking (id, document_id, status, error_message, created_at, updated_at)
  - [x] Create `sqlite_schema.sql` script with proper data types and constraints
  - [x] Add indexes for performance on commonly queried fields
- [x] Task 2: Create Supabase PostgreSQL schema script (AC: 2)
  - [x] Enable `pgvector` extension for vector embeddings
  - [x] Define `document_chunks` table for storing text chunks and vector embeddings
  - [x] Include metadata fields for biblical citations (book, chapter, verse, version)
  - [x] Include metadata fields for theological sources (document_name, page_number, section)
  - [x] Create `supabase_schema.sql` script with vector column types
  - [x] Add indexes for vector similarity search performance
- [x] Task 3: Create database setup documentation (AC: 3)
  - [x] Document SQLite database initialization process
  - [x] Document Supabase setup instructions including pgvector configuration
  - [x] Create step-by-step setup guide in `apps/api/database/README.md`
  - [x] Include connection string examples and environment variables needed
- [x] Task 4: Validate schema designs
  - [x] Ensure naming conventions follow snake_case standards
  - [x] Verify foreign key relationships are properly defined
  - [x] Check that all data types align with application requirements
  - [x] Validate vector dimensions match OpenAI embedding model specifications

## Dev Notes

### Previous Story Insights
From Story 1.3 completion:
- Frontend React application is successfully running and styled with TailwindCSS
- Monorepo structure is established and functional
- Backend FastAPI application from Story 1.2 is running on port 8001
- Project follows established coding standards and naming conventions

### Database Architecture Requirements
[Source: docs/prd/technical-assumptions.md]
- **Backend Stack:** Python, FastAPI, SQLite, Supabase (Postgres w/ pgvector), JWT, bcrypt, SSE, OpenAI API, Celery/Redis
- **Local Database:** SQLite for metadata storage
- **Vector Database:** Supabase (PostgreSQL with pgvector) for embeddings

[Source: docs/architecture/high-level-architecture.md]
- **Technical Summary:** Backend uses SQLite Database for metadata and Supabase for vector database
- **Architecture Pattern:** Monolith with PocketFlow pattern for AI workflows

### Data Models and Schema Requirements
[Source: docs/prd/epic-and-story-details.md]

**Users Table (Epic 2.1):**
- Fields: unique ID, email, hashed password, role, status
- Password field must never store plain-text passwords
- Status values: 'pending', 'approved', 'denied'
- Role values: 'user', 'admin'

**Documents Table (Epic 3.2):**
- Fields: ID, filename, document_type, file_path, status, metadata
- Document types: 'biblical', 'theological', 'other' [Source: docs/prd/project-glossary-and-data-dictionary.md]
- Status values: 'queued', 'processing', 'completed', 'failed'

**Document Chunks Table (Epic 4.4):**
- Text content storage with vector embeddings
- Biblical citation metadata: version, book, chapter, verse number [Source: docs/prd/requirements.md#FR9]
- Theological citation metadata: document name, page/section number [Source: docs/prd/requirements.md#FR9]
- Vector embeddings from OpenAI text-embedding-ada-002 model

### Coding Standards for Database Schema
[Source: docs/architecture/coding-standards.md#database-naming]
- Use snake_case for table names: `users`, `document_metadata`, `processing_jobs`
- Use snake_case for column names: `user_id`, `created_at`, `processing_status`

[Source: docs/architecture/coding-standards.md#api-naming]
- Use camelCase for JSON keys when interfacing with API: `userId`, `createdAt`, `processingStatus`

### File Locations
Based on existing monorepo structure and backend architecture:
- **Database Scripts Location:** `apps/api/database/`
- **SQLite Schema:** `apps/api/database/sqlite_schema.sql`
- **Supabase Schema:** `apps/api/database/supabase_schema.sql`
- **Documentation:** `apps/api/database/README.md`
- **SQLite Database File:** `apps/api/database/local.db` (when created)

### Technical Constraints and Requirements
[Source: docs/prd/requirements.md]
- **NFR5:** System uses SQLite for local metadata and Supabase (PostgreSQL with pgvector) for embeddings
- **FR16:** Support multiple distinct versions of biblical texts
- **FR17:** Support retrieval of large, contiguous blocks of biblical text

**Vector Database Specifications:**
- OpenAI text-embedding-ada-002 model produces 1536-dimensional vectors
- pgvector extension required for similarity search functionality
- Indexes needed for efficient vector similarity queries

**Processing Pipeline Requirements:**
- Document processing status tracking through multiple states
- Error logging and recovery capabilities
- Metadata preservation through chunking and embedding process

### Testing
No specific testing guidance found in architecture docs for database schema.
Testing requirements for this foundational story:
- Verify SQL scripts execute without errors on target databases
- Confirm all tables are created with correct structure and constraints
- Test foreign key relationships function properly
- Validate indexes are created and improve query performance
- Ensure vector columns accept embedding data in correct format

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-07-22 | 1.0 | Initial story creation for database schema initialization | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
Claude Sonnet 4 (claude-sonnet-4-20250514)

### Debug Log References
- SQLite schema validation: Created test database and verified table creation, constraints, and foreign key relationships
- Constraint testing: Validated CHECK constraints for role, status, and document_type fields
- Index verification: Confirmed all indexes were created properly for performance optimization

### Completion Notes List
- Successfully created comprehensive SQLite schema with all required tables, constraints, and indexes
- Implemented PostgreSQL schema with pgvector extension and vector similarity search functions
- Added automatic timestamp triggers for both databases to maintain updated_at fields
- Created detailed documentation with setup instructions, environment variables, and troubleshooting guide
- Validated schema designs meet all coding standards (snake_case naming) and application requirements
- Vector dimensions confirmed as 1536 to match OpenAI text-embedding-ada-002 model specifications

### File List
**New Files Created:**
- `apps/api/database/sqlite_schema.sql` - SQLite database schema with users, documents, and processing_jobs tables
- `apps/api/database/supabase_schema.sql` - PostgreSQL schema with pgvector extension and document_chunks table
- `apps/api/database/README.md` - Comprehensive database setup and configuration guide
- `apps/api/database/test_schemas.py` - Comprehensive test suite for schema validation

**Modified Files:**
- None (this is foundational schema creation)

## QA Results

### Review Date: 2025-07-22
### Reviewed By: Quinn (Senior Developer QA)

### Code Quality Assessment
The database schema implementation is **excellent** and demonstrates senior-level architectural thinking. The developer has created comprehensive schemas that not only meet all acceptance criteria but exceed expectations with thoughtful design patterns, performance optimizations, and maintainability features. The implementation shows deep understanding of both SQLite and PostgreSQL vector database requirements.

### Refactoring Performed
No refactoring was required. The implementation is already at production quality with:
- Proper constraint definitions and data integrity
- Well-optimized indexes for performance
- Automatic timestamp management via triggers
- Comprehensive documentation and setup guides
- Production-ready security considerations (RLS policies)

### Compliance Check
- **Coding Standards:** ✓ **Perfect** - All naming follows snake_case conventions exactly as specified
- **Project Structure:** ✓ **Perfect** - Files placed in correct `apps/api/database/` location per monorepo structure
- **Testing Strategy:** ✓ **Excellent** - Comprehensive test suite validates schema integrity, constraints, and indexes
- **All ACs Met:** ✓ **Perfect** - All acceptance criteria fully implemented with additional value-adds

### PocketFlow Coding Requirements Audit

#### PocketFlow Architecture Pattern Compliance
- ✅ **Database Foundation Ready**: Schemas provide the data foundation needed for PocketFlow pipeline implementation
- ✅ **Stateless Design Support**: Tables designed to support stateless Node operations with proper job tracking
- ✅ **Modular Data Architecture**: Clear separation between metadata (SQLite) and vector operations (Supabase)
- ✅ **Pipeline-Ready Schema**: `processing_jobs` table perfectly supports asynchronous PocketFlow workflow tracking

#### PocketFlow-Specific Requirements Validation
- ✅ **NFR7 Compliance**: Database schema designed to support PocketFlow architectural pattern implementation
- ✅ **Node Isolation Support**: Proper foreign key relationships enable independent Node operations
- ✅ **Shared Store Foundation**: Vector database schema ready for PocketFlow shared state management
- ✅ **Error Handling**: Comprehensive error tracking in `processing_jobs` table supports Node failure recovery

#### Project Principles Compliance
- ✅ **Principle #2 (Standardized Terminology)**: All naming follows established glossary conventions
- ✅ **Principle #4 (Clear Architecture)**: Database schema clearly documented with setup instructions
- ✅ **Principle #5 (Dependency Management)**: Exact version specifications provided for database engines

### Improvements Checklist
All items were already handled correctly by the developer:

- [x] SQLite schema with proper constraints and indexes implemented
- [x] PostgreSQL schema with pgvector extension and vector functions implemented
- [x] Comprehensive documentation with setup instructions provided
- [x] Test suite for schema validation created
- [x] Naming conventions perfectly follow snake_case standards
- [x] Foreign key relationships properly defined
- [x] Performance indexes strategically placed
- [x] Automatic timestamp management via triggers
- [x] Row Level Security policies prepared for future auth implementation
- [x] Vector search functions optimized for OpenAI embedding dimensions

### Security Review
**Excellent security considerations:**
- Password hashing field properly named (`password_hash` - never stores plain text)
- Row Level Security (RLS) policies prepared in Supabase schema
- Proper constraint validations prevent invalid data states
- Foreign key constraints maintain referential integrity
- No SQL injection vulnerabilities in schema design

### Performance Considerations
**Outstanding performance optimization:**
- Strategic indexes on all commonly queried fields
- Vector similarity search indexes with proper operator classes
- Composite indexes for complex query patterns
- Proper vector dimension sizing (1536) for OpenAI compatibility
- Efficient trigger-based timestamp management

### PocketFlow Integration Assessment
**Perfect foundation for PocketFlow implementation:**
- Schema supports the modular, stateless Node architecture required by PocketFlow
- Job tracking table enables proper pipeline orchestration
- Vector database design supports AI workflow requirements
- Metadata separation allows for efficient Node communication
- Error handling schema supports Node failure recovery patterns

### Final Status
✓ **Approved - Ready for Done**

**Outstanding Work:** This implementation demonstrates exceptional architectural thinking and sets an excellent foundation for the PocketFlow pipeline. The developer has anticipated future requirements and delivered a production-ready database layer that exceeds all acceptance criteria while maintaining perfect compliance with project principles and PocketFlow requirements.