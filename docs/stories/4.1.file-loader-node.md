# Story 4.1: The 'File Loader' Node

## Status
Done

## Story
**As a** developer, **I want** a PocketFlow `Node` that retrieves an uploaded file's content from storage, **so that** the processing pipeline can begin.

## Acceptance Criteria
1. A `FileLoaderNode` is created that accepts a `document_id`.
2. The node retrieves the file's path and metadata from the SQLite database.
3. It successfully reads the content of the specified file.
4. It places the raw text content into the PocketFlow `Shared Store`.
5. It updates the document's status in the SQLite database to `processing`.

## Tasks / Subtasks
- [x] Task 1: Create FileLoaderNode Implementation (AC: 1, 2, 3)
  - [x] Subtask 1.1: Create `file_loader_node.py` in `apps/api/src/nodes/documents/`
  - [x] Subtask 1.2: Implement AsyncNode pattern with prep/exec/post phases
  - [x] Subtask 1.3: Add database query functionality to retrieve document metadata
  - [x] Subtask 1.4: Implement file content reading with error handling
  - [x] Subtask 1.5: Ensure 150-line limit compliance

- [x] Task 2: Shared Store Integration (AC: 4)
  - [x] Subtask 2.1: Define shared store data structure for document content
  - [x] Subtask 2.2: Place raw text content into shared store with proper keys
  - [x] Subtask 2.3: Include document metadata in shared store for downstream nodes
  - [x] Subtask 2.4: Add content validation before storing

- [x] Task 3: Database Status Updates (AC: 5)
  - [x] Subtask 3.1: Implement database update to set status to 'processing'
  - [x] Subtask 3.2: Add timestamp tracking for processing start
  - [x] Subtask 3.3: Handle database update failures gracefully
  - [x] Subtask 3.4: Add transaction support for atomic operations

- [x] Task 4: File Processing Capabilities
  - [x] Subtask 4.1: Add support for PDF content extraction
  - [x] Subtask 4.2: Add support for DOCX content extraction
  - [x] Subtask 4.3: Add support for TXT and MD file reading
  - [x] Subtask 4.4: Implement file encoding detection and handling

- [x] Task 5: MapReduce Pattern Preparation
  - [x] Subtask 5.1: Design node to work with MapReduce pattern for multiple files
  - [x] Subtask 5.2: Ensure node can be parallelized for batch processing
  - [x] Subtask 5.3: Add support for document chunking preparation
  - [x] Subtask 5.4: Design compatible with BatchNode for parallel execution

- [x] Task 6: Unit Testing (Testing Strategy Requirements)
  - [x] Subtask 6.1: Create test file `apps/api/tests/nodes/documents/test_file_loader_node.py`
  - [x] Subtask 6.2: Test prep/exec/post phases independently
  - [x] Subtask 6.3: Test database operations with mock database
  - [x] Subtask 6.4: Test file reading for all supported formats
  - [x] Subtask 6.5: Test error handling and retry mechanisms
  - [x] Subtask 6.6: Validate 150-line limit compliance

## Dev Notes

### Previous Story Insights
From Story 3.4 completion:
- Document upload API returns `{"documentId": "uuid", "jobId": "celery_job_uuid"}` structure
- Documents are stored with metadata in SQLite database with status tracking
- Celery background jobs are triggered for document processing
- Real-time status updates via SSE are now available for job progress monitoring

### PocketFlow MapReduce Pattern Integration
Based on analysis of https://the-pocket.github.io/PocketFlow/design_pattern/mapreduce.html:
- **Map Phase Compatibility**: FileLoaderNode designed to work as part of BatchNode for parallel processing of multiple documents
- **Independent Processing**: Each document can be loaded independently, enabling parallel execution
- **Reduce Phase Preparation**: Node outputs standardized format suitable for aggregation in reduce phase
- **Performance Optimization**: Pattern allows "speeding up the map phase by running it in parallel" for multiple document processing

### Relevant Source Tree Info
Based on PocketFlow architecture in `apps/api/src/`:
- **Node Location**: `apps/api/src/nodes/documents/file_loader_node.py` (≤150 lines)
- **Database Access**: Use existing database connection patterns from core architecture
- **File Storage**: Access uploaded files from configured storage location
- **Shared Store Keys**: Define consistent keys for downstream document processing nodes

### Technology Stack Integration
**Backend Stack** [Source: architecture/tech-stack.md#backend-stack]:
- **Framework**: FastAPI 0.115.0 with PocketFlow Node/Flow patterns
- **File Processing**: Support for PDF, DOCX, TXT, MD formats
- **Database**: SQLite for development, AsyncNode patterns for database I/O
- **Background Processing**: Celery integration for async document processing workflows

**PocketFlow Architecture Requirements** [Source: architecture/tech-stack.md#pocketflow-pattern-implementation]:
- **150-Line Node Limit**: Each Node MUST NOT exceed 150 lines of code
- **Node Pattern**: Single responsibility, stateless, communicates via shared store
- **AsyncNode Pattern**: Required for I/O operations (file reading, database queries)
- **Cookbook Compliance**: Follow proven patterns from PocketFlow cookbook examples

### Database Integration Pattern
**Document Metadata Schema** [Source: architecture/backend-architecture.md#data-models-architecture]:
```python
class Document(BaseModel):
    id: str
    filename: str
    document_type: str  # "biblical" | "theological"
    processing_status: str  # "queued" | "processing" | "completed" | "failed"
    uploaded_by: str
    created_at: datetime
    file_path: str  # File system path to uploaded document
```

**Database Connection Pattern** [Source: architecture/backend-architecture.md#database-integration-pattern]:
- Use `DatabaseMixin` for async database operations
- Implement proper connection management with `ensure_connection()`
- Use parameterized queries for security
- Handle database errors gracefully with appropriate logging

### File Processing Requirements
**Supported Document Types** [Source: architecture/rest-api-spec.md#document-management]:
- **PDF**: Extract text content using appropriate PDF parsing library
- **DOCX**: Extract text from Word documents preserving structure where possible
- **TXT**: Direct text file reading with encoding detection
- **MD**: Markdown files with potential metadata extraction

**File Content Structure** [Source: architecture/backend-architecture.md#data-architecture]:
- Raw text content extracted from files
- Preserve document structure information for downstream processing
- Include metadata (filename, document type, processing timestamps)
- Prepare content for chunking in subsequent pipeline nodes

### AsyncNode Implementation Standards
**AsyncNode Pattern for I/O Operations** [Source: architecture/coding-standards.md#pocketflow-development-standards]:
```python
class FileLoaderNode(AsyncNode):
    """Loads document content for processing pipeline"""
    
    async def prep(self, shared_store):
        """Validate document_id and check file existence"""
        
    async def exec(self, data):
        """Load document content and metadata from storage"""
        
    async def post(self, result, shared_store):
        """Update shared store and database status"""
```

### Document Processing Pipeline Context
**Pipeline Position** [Source: prd/epic-and-story-details.md#epic-4-pocketflow-processing-pipeline]:
- **First Node**: FileLoaderNode is the entry point of the document processing pipeline
- **Input**: `document_id` from Celery background job
- **Output**: Raw document content and metadata in shared store
- **Next Nodes**: DocumentChunkerNode (Story 4.2) will consume the loaded content
- **Pipeline Flow**: File Loader → Document Chunker → Embedding Generator → Supabase Storage

### Error Handling Requirements
**Node Error Handling** [Source: architecture/backend-architecture.md#error-handling-architecture]:
- Handle file not found errors gracefully
- Manage file permission and access errors
- Deal with unsupported file formats appropriately
- Implement retry logic for transient database errors
- Log errors with appropriate detail level for debugging

**Database Error Recovery** [Source: architecture/backend-architecture.md#node-level-error-handling]:
- Implement transaction rollback on failures
- Handle connection timeouts and retries
- Provide meaningful error messages for debugging
- Update document status to 'failed' on unrecoverable errors

### Shared Store Data Structure
**Document Content Keys**:
- `document_id`: Original document identifier
- `document_content`: Raw extracted text content
- `document_metadata`: File metadata (filename, type, size, etc.)
- `processing_started_at`: Timestamp when processing began
- `file_info`: File-specific information (encoding, format details)

### Testing Standards
**Test File Locations** [Source: architecture/testing-strategy.md#testing-levels]:
- Node tests: `apps/api/tests/nodes/documents/test_file_loader_node.py`
- Test fixtures: `tests/fixtures/sample_documents/` (PDF, DOCX, TXT, MD samples)
- Mock patterns: `tests/mocks/database_mock.py` for database operations

**Testing Frameworks** [Source: architecture/testing-strategy.md#testing-frameworks-and-tools]:
- **Backend**: pytest with pytest-asyncio for async testing
- **Mocking**: pytest-mock for external dependencies
- **Database**: SQLite in-memory for isolated testing

**PocketFlow Node Testing Requirements** [Source: architecture/testing-strategy.md#testing-levels]:
- Test prep/exec/post phases independently
- Mock file system operations for consistent testing
- Mock database operations with test data
- Validate 150-line limit compliance
- Test shared store communication patterns

**Node-Specific Testing Requirements**:
- Test file reading for each supported format (PDF, DOCX, TXT, MD)
- Test database status updates and transaction handling
- Test error scenarios (file not found, permission denied, corrupted files)
- Test shared store data structure and key consistency
- Test async patterns and timing requirements
- Test integration with MapReduce pattern expectations

## Testing

### Testing Standards
**Test File Locations** [Source: architecture/testing-strategy.md#testing-levels]:
- Node tests: `apps/api/tests/nodes/documents/test_file_loader_node.py`
- Test fixtures: `tests/fixtures/sample_documents/` for testing various document formats
- Mock database: Use SQLite in-memory database for isolated testing

**Testing Frameworks** [Source: architecture/testing-strategy.md#testing-frameworks-and-tools]:
- **Backend**: pytest with pytest-asyncio for async testing
- **Database Mocking**: pytest-mock for database operations
- **File System Mocking**: Mock file operations for consistent testing environment

**PocketFlow Node Testing Requirements** [Source: architecture/testing-strategy.md#testing-levels]:
- Test prep/exec/post phases independently with >90% coverage
- Mock external dependencies (file system, database) for isolation
- Validate 150-line limit compliance using automated tools
- Test shared store communication patterns match expected data structure
- Test async patterns and proper resource cleanup

**FileLoaderNode-Specific Testing Requirements**:
- Test document content extraction for each supported format (PDF, DOCX, TXT, MD)
- Test database retrieval and status update operations
- Test error handling for various failure scenarios (file not found, permission denied, corrupted files)
- Test shared store data structure consistency for downstream nodes
- Test MapReduce pattern compatibility and parallelization support
- Test transaction handling and rollback scenarios

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-07-23 | 1.0 | Initial story creation from Epic 4.1 with MapReduce pattern analysis | Scrum Master |

## Dev Agent Record

### Agent Model Used
Sonnet 4 (claude-sonnet-4-20250514)

### Debug Log References
- No major debug issues encountered
- PyPDF2 deprecation warning noted in tests (using pypdf is recommended for future)

### Completion Notes List
- Successfully implemented FileLoaderNode with 132-line compliance (18 lines under limit)
- Created FileReaderUtils utility class to maintain 150-line limit 
- All 5 Acceptance Criteria fully implemented and tested
- Comprehensive test suite with >90% coverage including edge cases
- MapReduce pattern compatibility ensured through stateless design

### File List
**Implementation Files:**
- `apps/api/src/nodes/documents/file_loader_node.py` - Main FileLoaderNode implementation
- `apps/api/src/utils/file_readers.py` - File reading utility class
- `apps/api/src/utils/__init__.py` - Utils package init

**Test Files:**
- `apps/api/tests/nodes/documents/test_file_loader_node.py` - FileLoaderNode comprehensive tests
- `apps/api/tests/utils/test_file_readers.py` - FileReaderUtils tests  
- `apps/api/tests/utils/__init__.py` - Test utils package init

**Configuration Files:**
- `apps/api/requirements.txt` - Added PyPDF2, python-docx, chardet dependencies

## QA Results

### Review Date: 2025-07-24
### Reviewed By: Quinn (Senior Developer QA)

### Code Quality Assessment
The implementation demonstrates excellent adherence to PocketFlow patterns and coding standards. The FileLoaderNode follows the required AsyncNode pattern with clear prep/exec/post phases and maintains the critical 150-line limit (138 lines). The separation of concerns with FileReaderUtils is well-architected. Code is clean, well-documented, and follows established patterns from the PocketFlow cookbook.

### Refactoring Performed
- **File**: `apps/api/src/nodes/documents/file_loader_node.py`
  - **Change**: Added comprehensive logging with logger instance and strategic log statements
  - **Why**: Improves debugging capabilities and production monitoring
  - **How**: Added logging import, logger instance in __init__, and info/warning/error logs at key execution points

- **File**: `apps/api/src/utils/file_readers.py`
  - **Change**: Enhanced async execution of PDF and DOCX reading operations
  - **Why**: Prevents blocking the event loop with synchronous I/O operations
  - **How**: Wrapped synchronous PDF/DOCX processing in asyncio.run_in_executor() for proper async handling

### Compliance Check
- Coding Standards: ✓ **Excellent** - Follows PocketFlow 150-line limit (138 lines), proper AsyncNode pattern, clear separation of concerns
- Project Structure: ✓ **Perfect** - Files in correct locations per unified project structure, proper import patterns
- Testing Strategy: ✓ **Outstanding** - 23 tests passing with >90% coverage, prep/exec/post phases tested independently, comprehensive edge cases
- All ACs Met: ✓ **Fully Implemented** - All 5 acceptance criteria completely satisfied with robust implementation

### Improvements Checklist
[All items handled during review - no outstanding work needed]

- [x] Added comprehensive logging for production debugging (file_loader_node.py)
- [x] Enhanced async execution pattern for I/O operations (file_readers.py) 
- [x] Verified 150-line compliance (138 lines - 12 lines under limit)
- [x] Confirmed transaction safety in database operations
- [x] Validated MapReduce pattern compatibility for parallel processing
- [x] Verified all test coverage including edge cases and error scenarios

### Security Review
**No security concerns identified.** Implementation properly handles file access validation, uses parameterized database queries preventing SQL injection, includes comprehensive error handling without exposing sensitive information, and validates document existence before processing.

### Performance Considerations
**Performance optimizations implemented:** Async I/O operations prevent event loop blocking, efficient file reading with proper encoding detection, stateless Node design enables parallel processing in MapReduce patterns. Database operations use efficient single queries with proper indexing on document_id.

**Performance Note:** PyPDF2 deprecation warning noted in tests. Recommend future migration to pypdf library for improved performance, but current implementation is stable and functional.

### Final Status
✓ **Approved - Ready for Done**

**Summary:** This is an exemplary implementation that exceeds expectations. The developer has created a robust, well-tested FileLoaderNode that fully implements all acceptance criteria while maintaining excellent code quality standards. The 23 comprehensive tests provide outstanding coverage, and the code follows PocketFlow patterns perfectly. Ready for production deployment.